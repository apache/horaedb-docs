<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>设计文档 on Apache HoraeDB</title><link>https://horaedb.apache.org/cn/docs/design/</link><description>Recent content in 设计文档 on Apache HoraeDB</description><generator>Hugo</generator><language>cn</language><atom:link href="https://horaedb.apache.org/cn/docs/design/index.xml" rel="self" type="application/rss+xml"/><item><title>HoraeDB 架构介绍</title><link>https://horaedb.apache.org/cn/docs/design/architecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/design/architecture/</guid><description>本文目标 为想了解更多关于 HoraeDB 但不知道从何入手的开发者提供 HoraeDB 的概览 简要介绍 HoraeDB 的主要模块以及这些模块之间的联系，但不涉及它们实现的细节 动机 HoraeDB 是一个时序数据库，与经典时序数据库相比，HoraeDB 的目标是能够同时处理时序型和分析型两种模式的数据，并提供高效的读写。
在经典的时序数据库中，Tag 列（ InfluxDB 称之为 Tag，Prometheus 称之为 Label）通常会对其生成倒排索引，但在实际使用中，Tag 的基数在不同的场景中是不一样的 ———— 在某些场景下，Tag 的基数非常高（这种场景下的数据，我们称之为分析型数据），而基于倒排索引的读写要为此付出很高的代价。而另一方面，分析型数据库常用的扫描 + 剪枝方法，可以比较高效地处理这样的分析型数据。
因此 HoraeDB 的基本设计理念是采用混合存储格式和相应的查询方法，从而达到能够同时高效处理时序型数据和分析型数据。
架构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 ┌──────────────────────────────────────────┐ │ RPC Layer (HTTP/gRPC/MySQL) │ └──────────────────────────────────────────┘ ┌──────────────────────────────────────────┐ │ SQL Layer │ │ ┌─────────────────┐ ┌─────────────────┐ │ │ │ Parser │ │ Planner │ │ │ └─────────────────┘ └─────────────────┘ │ └──────────────────────────────────────────┘ ┌───────────────────┐ ┌───────────────────┐ │ Interpreter │ │ Catalog │ └───────────────────┘ └───────────────────┘ ┌──────────────────────────────────────────┐ │ Query Engine │ │ ┌─────────────────┐ ┌─────────────────┐ │ │ │ Optimizer │ │ Executor │ │ │ └─────────────────┘ └─────────────────┘ │ └──────────────────────────────────────────┘ ┌──────────────────────────────────────────┐ │ Pluggable Table Engine │ │ ┌────────────────────────────────────┐ │ │ │ Analytic │ │ │ │┌────────────────┐┌────────────────┐│ │ │ ││ Wal ││ Memtable ││ │ │ │└────────────────┘└────────────────┘│ │ │ │┌────────────────┐┌────────────────┐│ │ │ ││ Flush ││ Compaction ││ │ │ │└────────────────┘└────────────────┘│ │ │ │┌────────────────┐┌────────────────┐│ │ │ ││ Manifest ││ Object Store ││ │ │ │└────────────────┘└────────────────┘│ │ │ └────────────────────────────────────┘ │ │ ┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ │ │ Another Table Engine │ │ │ └ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ │ └──────────────────────────────────────────┘ 上图展示了 HoraeDB 单机版本的架构，下面将会介绍重要模块的细节。</description></item><item><title>集群模式</title><link>https://horaedb.apache.org/cn/docs/design/clustering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/design/clustering/</guid><description>注意：文章中提到的部分特性暂时还未实现。
整体架构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 ┌───────────────────────────────────────────────────────────────────────┐ │ │ │ HoraeMeta Cluster │ │ │ └───────────────────────────────────────────────────────────────────────┘ ▲ ▲ ▲ │ │ │ │ │ │ ▼ ▼ ▼ ┌───────┐Route Info ┌HoraeDB─────┬┬─┐ ┌HoraeDB─────┬┬─┐ ┌HoraeDB─────┬┬─┐ │client │◀────────▶ │ │ │TableN││ │ │ │ │TableN││ │ │ │ │TableN││ │ └───────┘Write/Query└──Shard(L)──┴┴─┘ └──Shard(F)──┴┴─┘ └──Shard(F)──┴┴─┘ │ │ ▲ ▲ │ │ │ │ Write─────────┐ ├────Sync───────┘ │ │ │ ┌────────┬▼───┴────┬──────────────────┐ Upload SST │ │ │ │ │ │WAL │Region N │ │ │Service │ │ │ │ └────────┴─────────┴──────────────────┘ ▼ ┌───────────────────────────────────────────────────────────────────────┐ │ │ │ Object Storage │ │ │ └───────────────────────────────────────────────────────────────────────┘ 上面给出来 HoraeDB 集群化方案的整体架构图，对于其中的一些名词做出解释：</description></item><item><title>存储引擎</title><link>https://horaedb.apache.org/cn/docs/design/storage/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/design/storage/</guid><description>存储引擎主要提供以下两个功能：
数据的持久化 在保证数据正确性的前提下，用最合理的方式来组织数据，来满足不同场景的查询需求 本篇文档就来介绍 HoraeDB 中存储引擎的内部实现，读者可以参考这里面的内容，来探索如何高效使用 HoraeDB。
整体架构 HoraeDB 是一种基于 share-nothing 架构的分布式存储系统，不同服务器之间的数据相互隔离，互不影响。每一个单机中的存储引擎是 LSM（Log-structured merge-tree）的一个变种，针对时序场景做了优化，下图展示了其主要组件的运作方式：
Write Ahead Log (WAL) 一次写入请求的数据会写到两个部分：
内存中的 memtable 可持久化的 WAL 由于 memtable 不是实时持久化到底层存储系统，因此需要用 WAL 来保证 memtable 中数据的可靠性。
另一方面，由于分布式架构的设计，要求 WAL 本身是高可用的，现在 HoraeDB 中，主要有以下几种实现：
本地磁盘（基于 RocksDB，无分布式高可用） Oceanbase Kafka Memtable Memtable 是一个内存的数据结构，用来保存最近写入的数据。一个表对应一个 memtable。
Memtable 默认是可读写的（称为 active），当写入达到一起阈值时，会变成只读的并且被一个新的 memtable 替换掉。只读的 memtable 会被后台线程以 SST 的形式写入到底层存储系统中，写入完成后，只读的 memtable 就可以被销毁，同时 WAL 中也可以删除对应部分的数据。
Sorted String Table（SST） SST 是数据的持久化格式，按照表主键的顺序存放，目前 HoraeDB 采用 parquet 格式来存储。
对于 HoraeDB 来说，SST 有一个重要特性： segment_duration，只有同一个 segment 内的 SST 才有可能进行合并操作。而且有了 segment，也方便淘汰过期的数据。</description></item><item><title>Shared Nothing 架构</title><link>https://horaedb.apache.org/cn/docs/design/shared_nothing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/design/shared_nothing/</guid><description>背景 在 集群 文章中介绍了 HoraeDB 的集群方案，简单总结一下就是：
计算存储分离； 由中心化的元数据中心，管理整个集群； 然而计算存储分离的架构下，有个重要的问题在于，在集群调度的过程中，如何保证在共享的存储层中的数据不会因为不同的计算节点访问导致数据损坏，一个简单的例子就是如果同一块数据块被多个计算节点同时更新，可能就会出现数据损坏。
而 HoraeDB 的解决方案是通过特定的机制，在共享存储的情况下达到了类似 Shared-Nothing 架构 的效果，也就是说存储层的数据经过一定规则的划分，可以保证在任何时刻最多只有一个 HoraeDB 实例可以对其进行更新，本文中，将这个特性定义成集群拓扑的正确性，如果这个正确性得到保证的话，那么数据就不会因为集群的灵活调度而受到损坏。
本文对于 Shared Nothing 架构的优劣不做赘述，主要分享一下，HoraeDB 集群方案是如何在计算存储分离的方案下，达到 Shared Nothing 的效果（即如何保证 集群拓扑的正确性）。
数据划分 为了达到 Shared Nothing 的效果，首先需要将数据在共享的存储层上面进行好逻辑和物理的划分。在 此前的集群介绍文章 中介绍了 Shard 的基本作用，作为集群的基本调度单元，同时也是数据分布的基本划分单元，不同的 Shard 在存储层对应的数据是隔离的：
在 WAL 中，写入的 Table 数据会按照 Shard 组织起来，按照 Shard 写入到 WAL 的不同区域中，不同的 Shard 在 WAL 中的数据是隔离开的； 在 Object Storage 中，数据的管理是按照 Table 来划分的，而 Shard 和 Table 之间的关系是一对多的关系，也就说，任何一个 Table 只属于一个 Shard，因此在 Object Storage 中，Shard 之间的数据也是隔离的； Shard Lock 在数据划分好之后，需要保证的就是在任何时刻，同一时刻最多只有一个 HoraeDB 实例能够更新 Shard 的数据。那么要如何保证这一点的呢？很自然地，通过锁可以达到互斥的效果，不过在分布式集群中，我们需要的是分布式锁。通过分布式锁，每一个 Shard 被分配给 HoraeDB 实例时，HoraeDB 必须先获取到相应的 Shard Lock，才能完成 Shard 的打开操作，对应地，当 Shard 关闭后，HoraeDB 实例也需要主动释放 Shard Lock。</description></item><item><title>分区表</title><link>https://horaedb.apache.org/cn/docs/design/table_partitioning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/design/table_partitioning/</guid><description>注意：此功能仍在开发中，API 将来可能会发生变化。
本章讨论 PartitionTable。
HoraeDB 使用的分区表语法类似于 MySQL 。
一般的分区表包括Range Partitioning、List Partitoning、Hash Partitioning和Key Partititioning。
HoraeDB 目前仅支持 Key Partitioning。
设计 与 MySQL 类似，分区表的不同部分作为单独的表存储在不同的位置。
目前设计，一个分区表可以在多个 HoraeDB 节点上打开，支持同时写入和查询，可以水平扩展。
如下图所示，在 node0 和 node1 上打开了PartitionTable，在 node2 和 node3 上打开了存放实际数据的物理子表。
┌───────────────────────┐ ┌───────────────────────┐ │Node0 │ │Node1 │ │ ┌────────────────┐ │ │ ┌────────────────┐ │ │ │ PartitionTable │ │ │ │ PartitionTable │ │ │ └────────────────┘ │ │ └────────────────┘ │ │ │ │ │ │ │ └────────────┼──────────┘ └───────────┼───────────┘ │ │ │ │ ┌───────────────────────┼─────────────────────────────┼───────────────────────┐ │ │ │ │ ┌────────────┼───────────────────────┼─────────────┐ ┌─────────────┼───────────────────────┼────────────┐ │Node2 │ │ │ │Node3 │ │ │ │ ▼ ▼ │ │ ▼ ▼ │ │ ┌─────────────────────┐ ┌─────────────────────┐ │ │ ┌─────────────────────┐ ┌─────────────────────┐ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ SubTable_0 │ │ SubTable_1 │ │ │ │ SubTable_2 │ │ SubTable_3 │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ └─────────────────────┘ └─────────────────────┘ │ │ └─────────────────────┘ └─────────────────────┘ │ │ │ │ │ └──────────────────────────────────────────────────┘ └──────────────────────────────────────────────────┘ Key 分区 Key Partitioning支持一列或多列计算，使用 HoraeDB 内置的 hash 算法进行计算。</description></item><item><title>基于 Kafka 的 WAL</title><link>https://horaedb.apache.org/cn/docs/design/wal_on_kafka/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/design/wal_on_kafka/</guid><description>架构 在本节中，将会介绍一种分布式 WAL 实现（基于 Kafka）。表的预写日志（write-ahead logs，以下简称日志）在本实现中是按 region 级别管理的，region 可以简单理解为多个表的共享日志文件。
如下图所示，在本实现中将 region 映射到 Kafka 中的 topic（只有一个 partition）。 通常一个 region 需要两个 topic ，一个用于存储日志，另一个用于存储元数据。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 ┌──────────────────────────┐ │ Kafka │ │ │ │ ...... │ │ │ │ ┌─────────────────────┐ │ │ │ Meta Topic │ │ │ │ │ │ Delete │ │ ┌─────────────────┐ │ │ ┌──────────────────────┐ ┌───────┼─┼─► Partition │ │ │ │ HoraeDB │ │ │ │ │ │ │ │ │ │ │ │ │ └─────────────────┘ │ │ │ ┌──────────────────┐ │ │ │ │ │ │ │ │ WAL │ │ │ │ └─────────────────────┘ │ │ │ .</description></item><item><title>基于 RocksDB 的 WAL</title><link>https://horaedb.apache.org/cn/docs/design/wal_on_rocksdb/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/design/wal_on_rocksdb/</guid><description>架构 在本节中，我们将介绍单机版 WAL 的实现（基于 RocksDB）。预写日志（write-ahead logs，以下简称日志）在本实现中是按表级别进行管理的，对应的数据结构为 TableUnit。为简单起见，所有相关数据（日志或元数据）都存储在单个 column family（RocksDB 中的概念，可以类比关系型数据库的表） 中。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ┌─────────────────────────┐ │ HoraeDB │ │ │ │ ┌─────────────────────┐ │ │ │ WAL │ │ │ │ │ │ │ │ ...... │ │ │ │ │ │ │ │ ┌────────────────┐ │ │ Write ─────┼─┼──► TableUnit │ │ │ │ │ │ │ │ │ Read ─────┼─┼──► ┌────────────┐ │ │ │ │ │ │ │ RocksDBRef │ │ │ │ │ │ │ └────────────┘ │ │ │ Delete ─────┼─┼──► │ │ │ │ │ └────────────────┘ │ │ │ │ .</description></item></channel></rss>