<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Horaedb on Apache HoraeDB</title><link>https://horaedb.apache.org/cn/</link><description>Recent content in Horaedb on Apache HoraeDB</description><generator>Hugo</generator><language>cn</language><atom:link href="https://horaedb.apache.org/cn/index.xml" rel="self" type="application/rss+xml"/><item><title>快速开始</title><link>https://horaedb.apache.org/cn/docs/getting-started/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/getting-started/</guid><description>本章介绍如何快速启动 HoraeDB。在这里你将会学到启动一个单机模式的 HoraeDB，然后使用 SQL 写入一些数据并查询结果。
启动 使用 HoraeDB docker 镜像 是一种最简单的启动方式；如果你还没有安装 Docker，请首先参考 这里 安装 Docker。
注意：请选择一个大于等于 v1.0.0 的 tag 镜像。
使用如下命令安装并启动一个单机版 HoraeDB。
1 2 3 4 5 docker run -d --name horaedb-server \ -p 8831:8831 \ -p 3307:3307 \ -p 5440:5440 \ ghcr.io/apache/horaedb-server:nightly-20231222-f57b3827 启动后 HoraeDB 会监听如下端口：
8831, gRPC port 3307, MySQL port 5440, HTTP port HTTP 协议是最简单的交互方式，接下来的演示会使用 HTTP 协议进行介绍。不过在生产环境，我们推荐使用 gRPC/MySQL。
自定义 docker 的配置 参考如下命令，可以自定义 docker 中 horaedb-server 的配置，并把数据目录 /data 挂载到 docker 母机的硬盘上。</description></item><item><title>HoraeDB 架构介绍</title><link>https://horaedb.apache.org/cn/docs/design/architecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/design/architecture/</guid><description>本文目标 为想了解更多关于 HoraeDB 但不知道从何入手的开发者提供 HoraeDB 的概览 简要介绍 HoraeDB 的主要模块以及这些模块之间的联系，但不涉及它们实现的细节 动机 HoraeDB 是一个时序数据库，与经典时序数据库相比，HoraeDB 的目标是能够同时处理时序型和分析型两种模式的数据，并提供高效的读写。
在经典的时序数据库中，Tag 列（ InfluxDB 称之为 Tag，Prometheus 称之为 Label）通常会对其生成倒排索引，但在实际使用中，Tag 的基数在不同的场景中是不一样的 ———— 在某些场景下，Tag 的基数非常高（这种场景下的数据，我们称之为分析型数据），而基于倒排索引的读写要为此付出很高的代价。而另一方面，分析型数据库常用的扫描 + 剪枝方法，可以比较高效地处理这样的分析型数据。
因此 HoraeDB 的基本设计理念是采用混合存储格式和相应的查询方法，从而达到能够同时高效处理时序型数据和分析型数据。
架构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 ┌──────────────────────────────────────────┐ │ RPC Layer (HTTP/gRPC/MySQL) │ └──────────────────────────────────────────┘ ┌──────────────────────────────────────────┐ │ SQL Layer │ │ ┌─────────────────┐ ┌─────────────────┐ │ │ │ Parser │ │ Planner │ │ │ └─────────────────┘ └─────────────────┘ │ └──────────────────────────────────────────┘ ┌───────────────────┐ ┌───────────────────┐ │ Interpreter │ │ Catalog │ └───────────────────┘ └───────────────────┘ ┌──────────────────────────────────────────┐ │ Query Engine │ │ ┌─────────────────┐ ┌─────────────────┐ │ │ │ Optimizer │ │ Executor │ │ │ └─────────────────┘ └─────────────────┘ │ └──────────────────────────────────────────┘ ┌──────────────────────────────────────────┐ │ Pluggable Table Engine │ │ ┌────────────────────────────────────┐ │ │ │ Analytic │ │ │ │┌────────────────┐┌────────────────┐│ │ │ ││ Wal ││ Memtable ││ │ │ │└────────────────┘└────────────────┘│ │ │ │┌────────────────┐┌────────────────┐│ │ │ ││ Flush ││ Compaction ││ │ │ │└────────────────┘└────────────────┘│ │ │ │┌────────────────┐┌────────────────┐│ │ │ ││ Manifest ││ Object Store ││ │ │ │└────────────────┘└────────────────┘│ │ │ └────────────────────────────────────┘ │ │ ┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ │ │ Another Table Engine │ │ │ └ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ │ └──────────────────────────────────────────┘ 上图展示了 HoraeDB 单机版本的架构，下面将会介绍重要模块的细节。</description></item><item><title>支持平台</title><link>https://horaedb.apache.org/cn/docs/dev/platform/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/dev/platform/</guid><description>作为一个开源的数据库，HoraeDB 可以部署在基于英特尔 /ARM 架构的服务器，以及常见的虚拟环境。
OS status Ubuntu LTS 16.06 or later ✅ CentOS 7.3 or later ✅ Red Hat Enterprise Linux 7.3 or later 7.x releases ✅ macOS 11 or later ✅ Windows ❌ 生产环境下 , Linux 是首选平台。 macOS 主要用在开发环境。</description></item><item><title>编译</title><link>https://horaedb.apache.org/cn/docs/dev/compile_run/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/dev/compile_run/</guid><description>为了编译 HoraeDB, 首先需要安装相关的依赖（包括 Rust 的工具链)。
依赖(Ubuntu20.04) 假设我们的开发环境是 Ubuntu20.04, 可以执行如下命令来安装所需的依赖。
1 sudo apt install git curl gcc g++ libssl-dev pkg-config cmake protobuf-compiler 需要注意的是，项目的编译对 cmake、gcc、g++等依赖项有版本要求。
如果你的开发环境是旧的 Linux 发行版，有必要手动安装这些依赖项的高版本。
依赖(MacOS) 如果你的开发环境是 MacOS ，可以使用如下命令手动安装这些依赖项的高版本。
安装命令行工具： 1 xcode-select --install 安装 cmake: 1 brew install cmake 安装 protobuf: 1 brew install protobuf Rust Rust 可以使用 rustup 来安装。 安装 Rust 后，进入 HoraeDB 工程目录，根据工具链文件指定的 Rust 版本会被自动下载。
执行后，你需要添加环境变量来使用 Rust 工具链。只要把下面的命令放到你的~/.bashrc或~/.bash_profile中即可。
1 source $HOME/.cargo/env 编译运行 注意：gcc 版本要求是 8, 更高的版本可能出现编译报错。该问题在 issue-1506 中跟进。</description></item><item><title>性能诊断</title><link>https://horaedb.apache.org/cn/docs/dev/profiling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/dev/profiling/</guid><description>CPU 剖析 HoraeDB 提供 CPU 剖析 http 接口 debug/profile/cpu.
例子:
// 60s CPU 采样数据 curl 0:5000/debug/profile/cpu/60 // 产出文件 /tmp/flamegraph_cpu.svg 内存剖析 HoraeDB 提供内存剖析 http 接口 debug/profile/heap.
安装依赖 sudo yum install -y jemalloc-devel ghostscript graphviz 例子:
// 开启 malloc prof export MALLOC_CONF=prof:true // 运行 horaedb-server ./horaedb-server .... // 60s 内存采样数据 curl -L &amp;#39;0:5000/debug/profile/heap/60&amp;#39; &amp;gt; /tmp/heap_profile jeprof --show_bytes --pdf /usr/bin/horaedb-server /tmp/heap_profile &amp;gt; profile_heap.pdf jeprof --show_bytes --svg /usr/bin/horaedb-server /tmp/heap_profile &amp;gt; profile_heap.svg</description></item><item><title>标识符</title><link>https://horaedb.apache.org/cn/docs/user-guide/sql/identifier/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/sql/identifier/</guid><description>HoraeDB 中表名、列名等标识符不能是保留关键字或以数字和标点符号开始，不过 HoraeDB 允许用反引号引用标识符（`）。在这种情况下，它可以是任何字符串，如 00_table 或 select。</description></item><item><title>集群模式</title><link>https://horaedb.apache.org/cn/docs/design/clustering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/design/clustering/</guid><description>注意：文章中提到的部分特性暂时还未实现。
整体架构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 ┌───────────────────────────────────────────────────────────────────────┐ │ │ │ HoraeMeta Cluster │ │ │ └───────────────────────────────────────────────────────────────────────┘ ▲ ▲ ▲ │ │ │ │ │ │ ▼ ▼ ▼ ┌───────┐Route Info ┌HoraeDB─────┬┬─┐ ┌HoraeDB─────┬┬─┐ ┌HoraeDB─────┬┬─┐ │client │◀────────▶ │ │ │TableN││ │ │ │ │TableN││ │ │ │ │TableN││ │ └───────┘Write/Query└──Shard(L)──┴┴─┘ └──Shard(F)──┴┴─┘ └──Shard(F)──┴┴─┘ │ │ ▲ ▲ │ │ │ │ Write─────────┐ ├────Sync───────┘ │ │ │ ┌────────┬▼───┴────┬──────────────────┐ Upload SST │ │ │ │ │ │WAL │Region N │ │ │Service │ │ │ │ └────────┴─────────┴──────────────────┘ ▼ ┌───────────────────────────────────────────────────────────────────────┐ │ │ │ Object Storage │ │ │ └───────────────────────────────────────────────────────────────────────┘ 上面给出来 HoraeDB 集群化方案的整体架构图，对于其中的一些名词做出解释：</description></item><item><title>RoadMap</title><link>https://horaedb.apache.org/cn/docs/dev/roadmap/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/dev/roadmap/</guid><description>v0.1.0 支持基于本地磁盘的 Standalone 版本 支持分析存储格式 支持 SQL v0.2.0 静态路由的分布式版本 远端存储支持阿里云 OSS 支持基于 OBKV的 WAL v0.3.0 发布多语言客户端，包括 Java, Rust 和 Python 支持使用 HoraeMeta 的静态集群 混合存储格式基本实现 v0.4.0 实现更复杂的集群方案，增强 HoraeDB 的可靠性和可扩展性 构建日常运行的、基于 TSBS 的压测任务 v1.0.0-alpha (Released) 基于 Apache Kafka 实现分布式 WAL 发布 Golang 客户端 优化时序场景下的查询性能 支持集群模式下表的动态转移 v1.0.0 正式发布 HoraeDB 和相关 SDK，并完成所有的 breaking changes 完成分区表的主要工作 优化查询性能，特别是云原生集群模式下，包括： 多级缓存 多种方式减少从远端获取的数据量(提高 SST 数据过滤精度) 提高获取远程对象存储数据的并发度 通过控制合并时的资源消耗，提高数据写入性能 Afterwards 随着对时序数据库及其各种使用情况的深入了解，我们的大部分工作将聚焦在性能、可靠性、可扩展性、易用性以及与开源社区的合作方面
增加支持 PromQL, InfluxQL, OpenTSDB 协议 提供基础的运维工具。特别包括如下： 适配云基础设施的部署工具，如 Kubernetes 加强自监控能力，特别是关键的日志和指标 开发多种工具，方便使用 HoraeDB，例如，数据导入和导出工具 探索新的存储格式，提高混合负载（分析和时序负载）的性能</description></item><item><title>存储引擎</title><link>https://horaedb.apache.org/cn/docs/design/storage/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/design/storage/</guid><description>存储引擎主要提供以下两个功能：
数据的持久化 在保证数据正确性的前提下，用最合理的方式来组织数据，来满足不同场景的查询需求 本篇文档就来介绍 HoraeDB 中存储引擎的内部实现，读者可以参考这里面的内容，来探索如何高效使用 HoraeDB。
整体架构 HoraeDB 是一种基于 share-nothing 架构的分布式存储系统，不同服务器之间的数据相互隔离，互不影响。每一个单机中的存储引擎是 LSM（Log-structured merge-tree）的一个变种，针对时序场景做了优化，下图展示了其主要组件的运作方式：
Write Ahead Log (WAL) 一次写入请求的数据会写到两个部分：
内存中的 memtable 可持久化的 WAL 由于 memtable 不是实时持久化到底层存储系统，因此需要用 WAL 来保证 memtable 中数据的可靠性。
另一方面，由于分布式架构的设计，要求 WAL 本身是高可用的，现在 HoraeDB 中，主要有以下几种实现：
本地磁盘（基于 RocksDB，无分布式高可用） Oceanbase Kafka Memtable Memtable 是一个内存的数据结构，用来保存最近写入的数据。一个表对应一个 memtable。
Memtable 默认是可读写的（称为 active），当写入达到一起阈值时，会变成只读的并且被一个新的 memtable 替换掉。只读的 memtable 会被后台线程以 SST 的形式写入到底层存储系统中，写入完成后，只读的 memtable 就可以被销毁，同时 WAL 中也可以删除对应部分的数据。
Sorted String Table（SST） SST 是数据的持久化格式，按照表主键的顺序存放，目前 HoraeDB 采用 parquet 格式来存储。
对于 HoraeDB 来说，SST 有一个重要特性： segment_duration，只有同一个 segment 内的 SST 才有可能进行合并操作。而且有了 segment，也方便淘汰过期的数据。</description></item><item><title>常用 SQL</title><link>https://horaedb.apache.org/cn/docs/user-guide/sql/utility/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/sql/utility/</guid><description>HoraeDB 中有许多实用的 SQL 工具，可以辅助表操作或查询检查。
查看建表语句 1 SHOW CREATE TABLE table_name; SHOW CREATE TABLE 返回指定表的当前版本的创建语句，包括列定义、表引擎和参数选项等。例如：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 -- create one table CREATE TABLE `t` (a bigint, b int default 3, c string default &amp;#39;x&amp;#39;, d smallint null, t timestamp NOT NULL, TIMESTAMP KEY(t)) ENGINE = Analytic; -- Result: affected_rows: 0 -- show how one table should be created.</description></item><item><title>配置项</title><link>https://horaedb.apache.org/cn/docs/user-guide/sql/engine_options/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/sql/engine_options/</guid><description>建表时可以使用下列的选项配置引擎：
enable_ttl：布尔类型，默认为 true，当一个表配置 TTL 时，早于 ttl 的数据不会被查询到并且会被删除。
ttl：duration 类型，默认值为7d，此项定义数据的生命周期，只在 enable_ttl 为 true 的情况下使用。
storage_format： string 类型，数据存储的格式，有两种可选:
columnar, 默认值 hybrid, 注意：此功能仍在开发中，将来可能会发生变化。 上述两种存储格式详见 存储格式 部分。
存储格式 HoraeDB 支持两种存储格式，一个是 columnar, 这是传统的列式格式，一个物理列中存储表的一个列。
1 2 3 4 5 6 7 8 9 | Timestamp | Device ID | Status Code | Tag 1 | Tag 2 | | --------- |---------- | ----------- | ----- | ----- | | 12:01 | A | 0 | v1 | v1 | | 12:01 | B | 0 | v2 | v2 | | 12:02 | A | 0 | v1 | v1 | | 12:02 | B | 1 | v2 | v2 | | 12:03 | A | 0 | v1 | v1 | | 12:03 | B | 0 | v2 | v2 | | .</description></item><item><title>预告：第一次线上会议</title><link>https://horaedb.apache.org/cn/blog/2024/first-online-meeting/</link><pubDate>Wed, 21 Aug 2024 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/blog/2024/first-online-meeting/</guid><description>各位开发者们，
欢迎大家参加我们的第一次线上会议！这次会议标志着我们团队在项目开发过程中的一个重要里程碑，也是我们合作共赢的开始。
会议目的 这次会议的主要目的是让大家相互认识，了解项目的总体目标，讨论开发的初步计划，并明确各自的角色和责任。我们希望通过此次会议，能够为接下来的工作奠定坚实的基础，并建立起一个高效、透明的沟通机制。
主要议题 Apache HoraeDB 项目现状介绍 新 Metric Engine 设计方案介绍 参会方式 入会链接：https://meeting.dingtalk.com/j/011mRkbIdqL
可通过浏览器直接入会，无需下载钉钉。
也欢迎感兴趣的朋友可以加入我们的社区（钉钉群、微信公众号等），获取社区最新动态。
会议时间 2024 年 08 月 27 日 周二，21:00-22:00 (GMT+8)</description></item><item><title>ALTER TABLE</title><link>https://horaedb.apache.org/cn/docs/user-guide/sql/ddl/alter_table/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/sql/ddl/alter_table/</guid><description>使用 ALTER TABLE 可以改变表的结构和参数 .
变更表结构 例如可以使用 ADD COLUMN 增加表的列 :
1 2 3 -- create a table and add a column to it CREATE TABLE `t`(a int, t timestamp NOT NULL, TIMESTAMP KEY(t)) ENGINE = Analytic; ALTER TABLE `t` ADD COLUMN (b string); 变更后的表结构如下：
-- DESCRIBE TABLE `t`; name type is_primary is_nullable is_tag t timestamp true false false tsid uint64 true false false a int false true false b string false true false 变更表参数 例如可以使用 MODIFY SETTING 修改表的参数 :</description></item><item><title>DROP TABLE</title><link>https://horaedb.apache.org/cn/docs/user-guide/sql/ddl/drop_table/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/sql/ddl/drop_table/</guid><description>基础语法 删除表的基础语法如下:
1 DROP TABLE [IF EXISTS] table_name Drop Table 用来删除一个表，请谨慎使用这个语句，因为会同时删除表的定义和表的数据，并且无法恢复。</description></item><item><title>Go</title><link>https://horaedb.apache.org/cn/docs/user-guide/sdk/go/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/sdk/go/</guid><description>安装 go get github.com/apache/incubator-horaedb-client-go 你可以在这里找到最新的版本 here.
如何使用 初始化客户端 1 2 3 client, err := horaedb.NewClient(endpoint, horaedb.Direct, horaedb.WithDefaultDatabase(&amp;#34;public&amp;#34;), // Client所使用的database ) 参数名称 说明 defaultDatabase 所使用的 database，可以被单个 Write 或者 SQLRequest 请求中的 database 覆盖 RPCMaxRecvMsgSize grpc MaxCallRecvMsgSize 配置, 默认是 1024 _ 1024 _ 1024 RouteMaxCacheSize 如果 router 客户端中的 路由缓存超过了这个值，将会淘汰最不活跃的直至降低这个阈值, 默认是 10000 注意： HoraeDB 当前仅支持预创建的 public database , 未来会支持多个 database。
管理表 HoraeDB 使用 SQL 来管理表格，比如创建表、删除表或者新增列等等，这和你在使用 SQL 管理其他的数据库时没有太大的区别。
为了方便使用，在使用 gRPC 的 write 接口进行写入时，如果某个表不存在，HoraeDB 会根据第一次的写入自动创建一个表。
当然你也可以通过 create table 语句来更精细化的管理的表（比如添加索引等）。</description></item><item><title>InfluxDB</title><link>https://horaedb.apache.org/cn/docs/user-guide/ecosystem/influxdb/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/ecosystem/influxdb/</guid><description>InfluxDB 是一个时间序列数据库，旨在处理高写入和查询负载。它是 TICK 堆栈的一个组成部分。InfluxDB 旨在用作涉及大量时间戳数据的任何用例的后备存储，包括 DevOps 监控、应用程序指标、物联网传感器数据和实时分析。
HoraeDB 支持 InfluxDB v1.8 写入和查询 API。
注意：用户需要将以下配置添加到服务器的配置中才能尝试 InfluxDB 写入/查询。
[server.default_schema_config] default_timestamp_column_name = &amp;#34;time&amp;#34; 写入 curl -i -XPOST &amp;#34;http://localhost:5440/influxdb/v1/write&amp;#34; --data-binary &amp;#39; demo,tag1=t1,tag2=t2 field1=90,field2=100 1679994647000 demo,tag1=t1,tag2=t2 field1=91,field2=101 1679994648000 demo,tag1=t11,tag2=t22 field1=90,field2=100 1679994647000 demo,tag1=t11,tag2=t22 field1=91,field2=101 1679994648000 &amp;#39; Post 的内容采用的是 InfluxDB line protocol 格式。
measurement 将映射到 HoraeDB 中的一个表，在首次写入时 server 会自动进行建表(注意：创建表的 TTL 是 7d，写入超过当前周期数据会被丢弃)。
例如，在上面插入数据时，HoraeDB 中将创建下表：
CREATE TABLE `demo` ( `tsid` uint64 NOT NULL, `time` timestamp NOT NULL, `field1` double, `field2` double, `tag1` string TAG, `tag2` string TAG, PRIMARY KEY (tsid, time), timestamp KEY (time)) 注意事项 InfluxDB 在写入时，时间戳精度默认是纳秒，HoraeDB 只支持毫秒级时间戳，用户可以通过 precision 参数指定数据精度，HoraeDB 内部会自动转成毫秒精度。 暂时不支持诸如 db 等查询参数 查询 1 curl -G &amp;#39;http://localhost:5440/influxdb/v1/query&amp;#39; --data-urlencode &amp;#39;q=SELECT * FROM &amp;#34;demo&amp;#34;&amp;#39; 查询结果和 InfluxDB 查询接口一致：</description></item><item><title>INSERT</title><link>https://horaedb.apache.org/cn/docs/user-guide/sql/dml/insert/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/sql/dml/insert/</guid><description>基础语法 写入数据的基础语法如下：
1 2 3 INSERT [INTO] tbl_name [(col_name [, col_name] ...)] { {VALUES | VALUE} (value_list) [, (value_list)] ... } 写入一行数据的示例如下：
1 INSERT INTO demo(`timestamp`, tag1) VALUES(1667374200022, &amp;#39;horaedb&amp;#39;)</description></item><item><title>Java</title><link>https://horaedb.apache.org/cn/docs/user-guide/sdk/java/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/sdk/java/</guid><description>介绍 HoraeDBClient 是 HoraeDB 的高性能 Java 版客户端。
环境要求 Java 8 及以上
依赖 1 2 3 4 5 &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;io.ceresdb&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;ceresdb-all&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${CERESDB.VERSION}&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; 最新的版本可以从这里获取。
初始化客户端 1 2 3 4 5 6 7 8 9 10 11 // CeresDB options final CeresDBOptions opts = CeresDBOptions.newBuilder(&amp;#34;127.0.0.1&amp;#34;, 8831, DIRECT) // 默认 gprc 端口号，DIRECT 模式 .database(&amp;#34;public&amp;#34;) // Client所使用的database，可被RequestContext的database覆盖 .writeMaxRetries(1) // 写入失败重试次数上限（只有部分错误 code 才会重试，比如路由表失效） .readMaxRetries(1) // 查询失败重试次数上限（只有部分错误 code 才会重试，比如路由表失效） .build(); final CeresDBClient client = new CeresDBClient(); if (!</description></item><item><title>NoMeta 模式</title><link>https://horaedb.apache.org/cn/docs/user-guide/cluster_deployment/no_meta/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/cluster_deployment/no_meta/</guid><description>注意：此功能仅供测试使用，不推荐生产使用，相关功能将来可能会发生变化。
本章介绍如何部署一个静态（无 HoraeMeta）的 HoraeDB 集群。
在没有 HoraeMeta 的情况下，利用 HoraeDB 服务端针对表名提供了可配置的路由功能即可实现集群化部署，为此我们需要提供一个包含路由规则的正确配置。根据这个配置，请求会被发送到集群中的每个 HoraeDB 实例。
目标 本文的目标是：在同一台机器上部署一个集群，这个集群包含两个 HoraeDB 实例。
如果想要部署一个更大规模的集群，参考此方案也可以进行部署。
准备配置文件 基础配置 HoraeDB 的基础配置如下：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [server] bind_addr = &amp;#34;0.0.0.0&amp;#34; http_port = 5440 grpc_port = 8831 [logger] level = &amp;#34;info&amp;#34; [tracing] dir = &amp;#34;/tmp/horaedb&amp;#34; [analytic.storage.object_store] type = &amp;#34;Local&amp;#34; data_dir = &amp;#34;/tmp/horaedb&amp;#34; [analytic.wal] type = &amp;#34;RocksDB&amp;#34; data_dir = &amp;#34;/tmp/horaedb&amp;#34; 为了在同一个机器上部署两个实例，我们需要为每个实例配置不同的服务端口和数据目录。</description></item><item><title>OpenTSDB</title><link>https://horaedb.apache.org/cn/docs/user-guide/ecosystem/opentsdb/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/ecosystem/opentsdb/</guid><description>OpenTSDB 是基于 HBase 的分布式、可伸缩的时间序列数据库。
写入 HoraeDB 遵循 OpenTSDB put 写入接口。
summary 和 detailed 还未支持。
curl --location &amp;#39;http://localhost:5440/opentsdb/api/put&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ -d &amp;#39;[{ &amp;#34;metric&amp;#34;: &amp;#34;sys.cpu.nice&amp;#34;, &amp;#34;timestamp&amp;#34;: 1692588459000, &amp;#34;value&amp;#34;: 18, &amp;#34;tags&amp;#34;: { &amp;#34;host&amp;#34;: &amp;#34;web01&amp;#34;, &amp;#34;dc&amp;#34;: &amp;#34;lga&amp;#34; } }, { &amp;#34;metric&amp;#34;: &amp;#34;sys.cpu.nice&amp;#34;, &amp;#34;timestamp&amp;#34;: 1692588459000, &amp;#34;value&amp;#34;: 18, &amp;#34;tags&amp;#34;: { &amp;#34;host&amp;#34;: &amp;#34;web01&amp;#34; } }]&amp;#39; metric 将映射到 HoraeDB 中的一个表，在首次写入时 server 会自动进行建表(注意：创建表的 TTL 是 7d，写入超过当前周期数据会被丢弃)。
例如，在上面插入数据时，HoraeDB 中将创建下表：
CREATE TABLE `sys.cpu.nice`( `tsid` uint64 NOT NULL, `timestamp` timestamp NOT NULL, `dc` string TAG, `host` string TAG, `value` bigint, PRIMARY KEY(tsid, timestamp), TIMESTAMP KEY(timestamp)) ENGINE = Analytic WITH(arena_block_size = &amp;#39;2097152&amp;#39;, compaction_strategy = &amp;#39;default&amp;#39;, compression = &amp;#39;ZSTD&amp;#39;, enable_ttl = &amp;#39;true&amp;#39;, num_rows_per_row_group = &amp;#39;8192&amp;#39;, segment_duration = &amp;#39;2h&amp;#39;, storage_format = &amp;#39;AUTO&amp;#39;, ttl = &amp;#39;7d&amp;#39;, update_mode = &amp;#39;OVERWRITE&amp;#39;, write_buffer_size = &amp;#39;33554432&amp;#39;) 查询 暂不支持 OpenTSDB 查询，tracking issue。</description></item><item><title>Prometheus</title><link>https://horaedb.apache.org/cn/docs/user-guide/ecosystem/prometheus/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/ecosystem/prometheus/</guid><description>Prometheus是一个流行的云原生监控工具，由于其可扩展性、可靠性和可伸缩性，被企业广泛采用。它用于从云原生服务（如 Kubernetes 和 OpenShift）中获取指标，并将其存储在时序数据库中。Prometheus 也很容易扩展，允许用户用其他数据库扩展其特性和功能。
HoraeDB 可以作为 Prometheus 的长期存储解决方案，同时支持远程读取和远程写入 API。
配置 你可以通过在prometheus.yml中添加以下几行来配置 Prometheus 使用 HoraeDB 作为一个远程存储：
1 2 3 4 remote_write: - url: &amp;#34;http://&amp;lt;address&amp;gt;:&amp;lt;http_port&amp;gt;/prom/v1/write&amp;#34; remote_read: - url: &amp;#34;http://&amp;lt;address&amp;gt;:&amp;lt;http_port&amp;gt;/prom/v1/read&amp;#34; 每一个指标都会对应一个 HoraeDB 中的表：
标签（labels）对应字符串类型的 tag 列 数据的时间戳对应一个 timestamp 类型的 timestmap 列 数据的值对应一个双精度浮点数类型的 value 列 比如有如下 Prometheus 指标：
up{env=&amp;#34;dev&amp;#34;, instance=&amp;#34;127.0.0.1:9090&amp;#34;, job=&amp;#34;prometheus-server&amp;#34;} 对应 HoraeDB 中如下的表(注意：创建表的 TTL 是 7d，写入超过当前周期数据会被丢弃)：
CREATE TABLE `up` ( `timestamp` timestamp NOT NULL, `tsid` uint64 NOT NULL, `env` string TAG, `instance` string TAG, `job` string TAG, `value` double, PRIMARY KEY (tsid, timestamp), timestamp KEY (timestamp) ); SELECT * FROM up; tsid timestamp env instance job value 12683162471309663278 1675824740880 dev 127.</description></item><item><title>Python</title><link>https://horaedb.apache.org/cn/docs/user-guide/sdk/python/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/sdk/python/</guid><description>介绍 horaedb-client 是 HoraeDB python 客户端.
借助于 PyO3，python 客户端的实现实际上是基于 rust 客户端 的封装。
本手册将会介绍 python client 的一些基本用法，其中涉及到的完整示例，可以查看该示例代码.
环境要求 Python &amp;gt;= 3.7 安装 1 pip install ceresdb-client 你可以在这里找到最新的版本 here.
初始化客户端 首先介绍下如何初始化客户端，代码示例如下：
1 2 3 4 5 6 7 8 9 10 11 12 13 import asyncio import datetime from ceresdb_client import Builder, RpcContext, PointBuilder, ValueBuilder, WriteRequest, SqlQueryRequest, Mode, RpcConfig rpc_config = RpcConfig() rpc_config = RpcConfig() rpc_config.thread_num = 1 rpc_config.default_write_timeout_ms = 1000 builder = Builder(&amp;#39;127.</description></item><item><title>Rust</title><link>https://horaedb.apache.org/cn/docs/user-guide/sdk/rust/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/sdk/rust/</guid><description>安装 1 cargo add ceresdb-client 你可以在这里找到最新的版本 here.
初始化客户端 首先，我们需要初始化客户端。
创建客户端的 builder，你必须设置 endpoint 和 mode： endpoint 是类似 &amp;ldquo;ip/domain_name:port&amp;rdquo; 形式的字符串。 mode 用于指定访问 HoraeDB 服务器的方式，关于 mode 的详细信息。 1 let mut builder = Builder::new(&amp;#34;ip/domain_name:port&amp;#34;, Mode::Direct/Mode::Proxy); 创建和设置 rpc_config，可以按需进行定义或者直接使用默认值，更多详细参数请参考这里： 1 2 3 4 5 6 let rpc_config = RpcConfig { thread_num: Some(1), default_write_timeout: Duration::from_millis(1000), ..Default::default() }; let builder = builder.rpc_config(rpc_config); 设置 default_database，这会在执行 RPC 请求时未通过 RpcContext 设置 database 的情况下，将被作为目标 database 使用。 1 let builder = builder.default_database(&amp;#34;public&amp;#34;); 最后，我们从 builder 中创建客户端： 1 let client = builder.</description></item><item><title>SELECT</title><link>https://horaedb.apache.org/cn/docs/user-guide/sql/dml/select/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/sql/dml/select/</guid><description>基础语法 数据查询的基础语法如下：
1 2 3 4 5 6 7 SELECT select_expr [, select_expr] ... FROM table_name [WHERE where_condition] [GROUP BY {col_name | expr} ... ] [ORDER BY {col_name | expr} [ASC | DESC] [LIMIT [offset,] row_count ] 数据查询的语法和 mysql 类似，示例如下：
1 SELECT * FROM `demo` WHERE time_stamp &amp;gt; &amp;#39;2022-10-11 00:00:00&amp;#39; AND time_stamp &amp;lt; &amp;#39;2022-10-12 00:00:00&amp;#39; LIMIT 10</description></item><item><title>Shared Nothing 架构</title><link>https://horaedb.apache.org/cn/docs/design/shared_nothing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/design/shared_nothing/</guid><description>背景 在 集群 文章中介绍了 HoraeDB 的集群方案，简单总结一下就是：
计算存储分离； 由中心化的元数据中心，管理整个集群； 然而计算存储分离的架构下，有个重要的问题在于，在集群调度的过程中，如何保证在共享的存储层中的数据不会因为不同的计算节点访问导致数据损坏，一个简单的例子就是如果同一块数据块被多个计算节点同时更新，可能就会出现数据损坏。
而 HoraeDB 的解决方案是通过特定的机制，在共享存储的情况下达到了类似 Shared-Nothing 架构 的效果，也就是说存储层的数据经过一定规则的划分，可以保证在任何时刻最多只有一个 HoraeDB 实例可以对其进行更新，本文中，将这个特性定义成集群拓扑的正确性，如果这个正确性得到保证的话，那么数据就不会因为集群的灵活调度而受到损坏。
本文对于 Shared Nothing 架构的优劣不做赘述，主要分享一下，HoraeDB 集群方案是如何在计算存储分离的方案下，达到 Shared Nothing 的效果（即如何保证 集群拓扑的正确性）。
数据划分 为了达到 Shared Nothing 的效果，首先需要将数据在共享的存储层上面进行好逻辑和物理的划分。在 此前的集群介绍文章 中介绍了 Shard 的基本作用，作为集群的基本调度单元，同时也是数据分布的基本划分单元，不同的 Shard 在存储层对应的数据是隔离的：
在 WAL 中，写入的 Table 数据会按照 Shard 组织起来，按照 Shard 写入到 WAL 的不同区域中，不同的 Shard 在 WAL 中的数据是隔离开的； 在 Object Storage 中，数据的管理是按照 Table 来划分的，而 Shard 和 Table 之间的关系是一对多的关系，也就说，任何一个 Table 只属于一个 Shard，因此在 Object Storage 中，Shard 之间的数据也是隔离的； Shard Lock 在数据划分好之后，需要保证的就是在任何时刻，同一时刻最多只有一个 HoraeDB 实例能够更新 Shard 的数据。那么要如何保证这一点的呢？很自然地，通过锁可以达到互斥的效果，不过在分布式集群中，我们需要的是分布式锁。通过分布式锁，每一个 Shard 被分配给 HoraeDB 实例时，HoraeDB 必须先获取到相应的 Shard Lock，才能完成 Shard 的打开操作，对应地，当 Shard 关闭后，HoraeDB 实例也需要主动释放 Shard Lock。</description></item><item><title>WithMeta 模式</title><link>https://horaedb.apache.org/cn/docs/user-guide/cluster_deployment/with_meta/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/cluster_deployment/with_meta/</guid><description>本文展示如何部署一个由 HoraeMeta 控制的 HoraeDB 集群，有了 HoraeMeta 提供的服务，如果 HoraeDB 使用存储不在本地的话，就可以实现很多分布式特性，比如水平扩容、负载均衡、服务高可用等。
部署 HoraeMeta HoraeMeta 是 HoraeDB 分布式模式的核心服务之一，用于管理 HoraeDB 节点的调度，为 HoraeDB 集群提供高可用、负载均衡、集群管控等能力。 HoraeMeta 本身通过嵌入式的 ETCD 保障高可用。此外，ETCD 的服务也被暴露给 HoraeDB 用于实现分布式锁使用。
编译打包 安装 Golang，版本号 &amp;gt;= 1.19。 在项目根目录下使用 make build 进行编译打包。 部署方式 启动配置 目前 HoraeMeta 支持以配置文件和环境变量两种方式来指定服务启动配置。我们提供了配置文件方式启动的示例，具体可以参考 config。 环境变量的配置优先级高于配置文件，当同时存在时，以环境变量为准。
动态拓扑和静态拓扑 即使使用了 HoraeMeta 来部署 HoraeDB 集群，也可以选择静态拓扑或动态拓扑。对于静态拓扑，表的分布在集群初始化后是静态的，而对于动态拓扑，表可以在不同的 HoraeDB 节点之间进行动态迁移以达到负载平衡或者 failover 的目的。但是动态拓扑只有在 HoraeDB 节点使用的存储是非本地的情况下才能启用，否则会因为表的数据是持久化在本地，当表转移到不同的 HoraeDB 节点时会导致数据损坏。
目前，HoraeMeta 默认关闭集群拓扑的动态调度，并且在本篇指南中，这个选项也不会被开启，因为指南中的例子采用的是本地存储。如果要启用动态调度，可以将 TOPOLOGY_TYPE 设置为 dynamic（默认为 static），之后负载均衡和 failover 将会起作用。但是需要注意的是，如果底层存储是本地磁盘，则不要启用它。
此外对于静态拓扑，参数 DEFAULT_CLUSTER_NODE_COUNT 表示已部署集群中 HoraeDB 节点的数量，应该被设置为 HoraeDB 服务器的实际机器数，这个参数非常重要，因为集群初始化完毕之后，HoraeDB 集群将无法再增减机器。</description></item><item><title>分区表</title><link>https://horaedb.apache.org/cn/docs/design/table_partitioning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/design/table_partitioning/</guid><description>注意：此功能仍在开发中，API 将来可能会发生变化。
本章讨论 PartitionTable。
HoraeDB 使用的分区表语法类似于 MySQL 。
一般的分区表包括Range Partitioning、List Partitoning、Hash Partitioning和Key Partititioning。
HoraeDB 目前仅支持 Key Partitioning。
设计 与 MySQL 类似，分区表的不同部分作为单独的表存储在不同的位置。
目前设计，一个分区表可以在多个 HoraeDB 节点上打开，支持同时写入和查询，可以水平扩展。
如下图所示，在 node0 和 node1 上打开了PartitionTable，在 node2 和 node3 上打开了存放实际数据的物理子表。
┌───────────────────────┐ ┌───────────────────────┐ │Node0 │ │Node1 │ │ ┌────────────────┐ │ │ ┌────────────────┐ │ │ │ PartitionTable │ │ │ │ PartitionTable │ │ │ └────────────────┘ │ │ └────────────────┘ │ │ │ │ │ │ │ └────────────┼──────────┘ └───────────┼───────────┘ │ │ │ │ ┌───────────────────────┼─────────────────────────────┼───────────────────────┐ │ │ │ │ ┌────────────┼───────────────────────┼─────────────┐ ┌─────────────┼───────────────────────┼────────────┐ │Node2 │ │ │ │Node3 │ │ │ │ ▼ ▼ │ │ ▼ ▼ │ │ ┌─────────────────────┐ ┌─────────────────────┐ │ │ ┌─────────────────────┐ ┌─────────────────────┐ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ SubTable_0 │ │ SubTable_1 │ │ │ │ SubTable_2 │ │ SubTable_3 │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ └─────────────────────┘ └─────────────────────┘ │ │ └─────────────────────┘ └─────────────────────┘ │ │ │ │ │ └──────────────────────────────────────────────────┘ └──────────────────────────────────────────────────┘ Key 分区 Key Partitioning支持一列或多列计算，使用 HoraeDB 内置的 hash 算法进行计算。</description></item><item><title>创建表</title><link>https://horaedb.apache.org/cn/docs/user-guide/sql/ddl/create_table/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/sql/ddl/create_table/</guid><description>基础语法 建表的基础语法如下 ( [] 之间的内容是可选部分):
1 2 3 4 CREATE TABLE [IF NOT EXISTS] table_name ( column_definitions ) ENGINE = engine_type [WITH ( table_options )]; 列定义的语法 :
1 column_name column_type [[NOT] NULL] {[TAG] | [TIMESTAMP KEY] | [PRIMARY KEY]} [DICTIONARY] [COMMENT &amp;#39;&amp;#39;] 表选项的语法是键-值对，值用单引号（'）来引用。例如：
1 ... WITH ( enable_ttl=&amp;#39;false&amp;#39; ) IF NOT EXISTS 添加 IF NOT EXISTS 时，HoraeDB 在表名已经存在时会忽略建表错误。
定义列 一个列的定义至少应该包含名称和类型部分，支持的类型见 这里。
列默认为可空，即 &amp;ldquo;NULL &amp;quot; 关键字是隐含的；添加 NOT NULL 时列不可为空。
1 2 3 4 5 6 7 -- this definition a_nullable int -- equals to a_nullable int NULL -- add NOT NULL to make it required b_not_null NOT NULL 定义列时可以使用相关的关键字将列标记为 特殊列。</description></item><item><title>基于 Kafka 的 WAL</title><link>https://horaedb.apache.org/cn/docs/design/wal_on_kafka/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/design/wal_on_kafka/</guid><description>架构 在本节中，将会介绍一种分布式 WAL 实现（基于 Kafka）。表的预写日志（write-ahead logs，以下简称日志）在本实现中是按 region 级别管理的，region 可以简单理解为多个表的共享日志文件。
如下图所示，在本实现中将 region 映射到 Kafka 中的 topic（只有一个 partition）。 通常一个 region 需要两个 topic ，一个用于存储日志，另一个用于存储元数据。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 ┌──────────────────────────┐ │ Kafka │ │ │ │ ...... │ │ │ │ ┌─────────────────────┐ │ │ │ Meta Topic │ │ │ │ │ │ Delete │ │ ┌─────────────────┐ │ │ ┌──────────────────────┐ ┌───────┼─┼─► Partition │ │ │ │ HoraeDB │ │ │ │ │ │ │ │ │ │ │ │ │ └─────────────────┘ │ │ │ ┌──────────────────┐ │ │ │ │ │ │ │ │ WAL │ │ │ │ └─────────────────────┘ │ │ │ .</description></item><item><title>基于 RocksDB 的 WAL</title><link>https://horaedb.apache.org/cn/docs/design/wal_on_rocksdb/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/design/wal_on_rocksdb/</guid><description>架构 在本节中，我们将介绍单机版 WAL 的实现（基于 RocksDB）。预写日志（write-ahead logs，以下简称日志）在本实现中是按表级别进行管理的，对应的数据结构为 TableUnit。为简单起见，所有相关数据（日志或元数据）都存储在单个 column family（RocksDB 中的概念，可以类比关系型数据库的表） 中。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ┌─────────────────────────┐ │ HoraeDB │ │ │ │ ┌─────────────────────┐ │ │ │ WAL │ │ │ │ │ │ │ │ ...... │ │ │ │ │ │ │ │ ┌────────────────┐ │ │ Write ─────┼─┼──► TableUnit │ │ │ │ │ │ │ │ │ Read ─────┼─┼──► ┌────────────┐ │ │ │ │ │ │ │ RocksDBRef │ │ │ │ │ │ │ └────────────┘ │ │ │ Delete ─────┼─┼──► │ │ │ │ │ └────────────────┘ │ │ │ │ .</description></item><item><title>数据类型</title><link>https://horaedb.apache.org/cn/docs/user-guide/sql/model/data_types/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/sql/model/data_types/</guid><description>HoraeDB 实现了 Table 模型，支持的数据类型和 MySQL 比较类似。 下列表格列出了 HoraeDB 的数据类型和 MySQL 的数据类型的对应关系。
支持的数据类型 (大小写不敏感) SQL HoraeDB null Null timestamp Timestamp double Double float Float string String Varbinary Varbinary uint64 UInt64 uint32 UInt32 uint16 UInt16 uint8 UInt8 int64/bigint Int64 int32/int Int32 int16/smallint Int16 int8/tinyint Int8 boolean Boolean date Date time Time</description></item><item><title>标量函数</title><link>https://horaedb.apache.org/cn/docs/user-guide/sql/scalar_functions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/sql/scalar_functions/</guid><description>HoraeDB SQL 基于 DataFusion 实现，支持的标量函数如下。更多详情请参考： Datafusion
数值函数 函数 描述 abs(x) 绝对值 acos(x) 反余弦 asin(x) 反正弦 atan(x) 反正切 atan2(y, x) y/x 的反正切 ceil(x) 小于或等于参数的最接近整数 cos(x) 余弦 exp(x) 指数 floor(x) 大于或等于参数的最接近整数 ln(x) 自然对数 log10(x) 以 10 为底的对数 log2(x) 以 2 为底的对数 power(base, exponent) 幂函数 round(x) 四舍五入 signum(x) 根据参数的正负返回 -1、0、+1 sin(x) 正弦 sqrt(x) 平方根 tan(x) 正切 trunc(x) 截断计算，取整（向零取整） 条件函数 函数 描述 coalesce 如果它的参数中有一个不为 null，则返回第一个参数，如果所有参数均为 null，则返回 null。当从数据库中检索数据用于显示时，它经常用于用默认值替换 null 值。 nullif 如果 value1 等于 value2，则返回 null 值；否则返回 value1。这可用于执行与 coalesce 表达式相反的操作 字符函数 函数 描述 ascii 返回参数的第一个字符的 ascii 数字编码。在 UTF8 编码下，返回字符的 Unicode 码点。在其他多字节编码中，参数必须是 ASCII 字符。 bit_length 返回字符串的比特位数。 btrim 从字符串的开头和结尾删除给定字符串中的字符组成的最长字符串 char_length 等效于 length。 character_length 等效于 length。 concat 将两个或多个字符串合并为一个字符串。 concat_ws 使用给定的分隔符组合两个值。 chr 根据数字码返回字符。 initcap 将字符串中每个单词的首字母大写。 left 返回字符串的指定最左边字符。 length 返回字符串中字符的数量。 lower 将字符串中的所有字符转换为它们的小写。 lpad 使用特定字符集将字符串左填充到给定长度。 ltrim 从字符串的开头删除由字符中的字符组成的最长字符串（默认为空格）。 md5 计算给定字符串的 MD5 散列值。 octet_length 等效于 length。 repeat 返回一个由输入字符串重复指定次数组成的字符串。 replace 替换字符串中所有子字符串的出现为新子字符串。 reverse 反转字符串。 right 返回字符串的指定最右边字符。 rpad 使用特定字符集将字符串右填充到给定长度。 rtrim 从字符串的结尾删除包含 characters 中任何字符的最长字符串。 digest 计算给定字符串的散列值。 split_part 按指定分隔符拆分字符串，并从结果数组中返回 starts_with 检查字符串是否以给定字符串开始 strpos 搜索字符串是否包含一个给定的字符串，并返回位置 substr 提取子字符串 translate 把字符串翻译成另一种字符集 Translates one set of characters into another.</description></item><item><title>特殊字段</title><link>https://horaedb.apache.org/cn/docs/user-guide/sql/model/special_columns/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/sql/model/special_columns/</guid><description>HoraeDB 的表的约束如下：
必须有主键 主键必须包含时间列，并且只能包含一个时间列 主键不可为空，并且主键的组成字段也不可为空 Timestamp 列 HoraeDB 的表必须包含一个时间戳列，对应时序数据中的时间，例如 OpenTSDB/Prometheus 的 timestamp。 时间戳列通过关键字 timestamp key 设置，例如 TIMESTAMP KEY(ts)。
Tag 列 Tag 关键字定义了一个字段作为标签列，和时序数据中的 tag 类似，例如 OpenTSDB 的 tag 或 Prometheus 的 label。
主键 主键用于数据去重和排序，由一些列和一个时间列组成。 主键可以通过以下一些方式设置：
使用 primary key 关键字 使用 tag 来自动生成 TSID，HoraeDB 默认将使用 (TSID,timestamp) 作为主键。 只设置时间戳列，HoraeDB 将使用 (timestamp) 作为主键。 注意：如果同时指定了主键和 Tag 列，那么 Tag 列只是一个额外的信息标识，不会影响主键生成逻辑。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 CREATE TABLE with_primary_key( ts TIMESTAMP NOT NULL, c1 STRING NOT NULL, c2 STRING NULL, c4 STRING NULL, c5 STRING NULL, TIMESTAMP KEY(ts), PRIMARY KEY(c1, ts) ) ENGINE=Analytic WITH (ttl=&amp;#39;7d&amp;#39;); CREATE TABLE with_tag( ts TIMESTAMP NOT NULL, c1 STRING TAG NOT NULL, c2 STRING TAG NULL, c3 STRING TAG NULL, c4 DOUBLE NULL, c5 STRING NULL, c6 STRING NULL, TIMESTAMP KEY(ts) ) ENGINE=Analytic WITH (ttl=&amp;#39;7d&amp;#39;); CREATE TABLE with_timestamp( ts TIMESTAMP NOT NULL, c1 STRING NOT NULL, c2 STRING NULL, c3 STRING NULL, c4 DOUBLE NULL, c5 STRING NULL, c6 STRING NULL, TIMESTAMP KEY(ts) ) ENGINE=Analytic WITH (ttl=&amp;#39;7d&amp;#39;); TSID 如果建表时没有设置主键，并且提供了 Tag 列，HoraeDB 会自动生成一个 TSID 列和时间戳列作为主键。TSID 由所有 Tag 列的 hash 值生成，本质上这是一种自动生成 ID 的机制。</description></item><item><title>监控</title><link>https://horaedb.apache.org/cn/docs/user-guide/operation/observability/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/operation/observability/</guid><description>HoraeDB 支持使用 Prometheus 和 Grafana 做自监控。
Prometheus Prometheus 是非常流行的系统和服务监控系统。
配置 把下面的配置保存到 prometheus.yml 文件中。比如，在 tmp 目录下，文件地址为 /tmp/prometheus.yml。
有两个 HoraeDB http 服务启动在 localhost:5440、localhost:5441。
1 2 3 4 5 6 7 8 global: scrape_interval: 30s scrape_configs: - job_name: horaedb-server static_configs: - targets: [your_ip:5440, your_ip:5441] labels: env: horaedbcluster Prometheus 详细配置见这里。
运行 你可以使用 docker 来运行 Prometheus。Docker 镜像在这里可以找到。
docker run \ -d --name=prometheus \ -p 9090:9090 \ -v /tmp/prometheus.yml:/etc/prometheus/prometheus.yml \ prom/prometheus:v2.41.0 更多 Prometheus 安装方法，参考这里。
Grafana Grafana 是一个非常流行的可观察性和数据可视化平台。</description></item><item><title>系统表</title><link>https://horaedb.apache.org/cn/docs/user-guide/operation/system_table/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/operation/system_table/</guid><description>查询 Table 信息 类似于 Mysql&amp;rsquo;s information_schema.tables, HoraeDB 提供 system.public.tables 存储表信息。
system.public.tables 表的列如下 :
timestamp([TimeStamp]) catalog([String]) schema([String]) table_name([String]) table_id([Uint64]) engine([String]) 通过表名查询表信息示例如下：
1 2 3 4 5 curl --location --request POST &amp;#39;http://localhost:5000/sql&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ -d &amp;#39;{ &amp;#34;query&amp;#34;: &amp;#34;select * from system.public.tables where `table_name`=\&amp;#34;my_table\&amp;#34;&amp;#34; }&amp;#39; 返回结果
1 2 3 4 5 6 7 8 9 10 11 { &amp;#34;rows&amp;#34;:[ { &amp;#34;timestamp&amp;#34;:0, &amp;#34;catalog&amp;#34;:&amp;#34;horaedb&amp;#34;, &amp;#34;schema&amp;#34;:&amp;#34;public&amp;#34;, &amp;#34;table_name&amp;#34;:&amp;#34;my_table&amp;#34;, &amp;#34;table_id&amp;#34;:3298534886446, &amp;#34;engine&amp;#34;:&amp;#34;Analytic&amp;#34; } }</description></item><item><title>聚合函数</title><link>https://horaedb.apache.org/cn/docs/user-guide/sql/aggregate_functions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/sql/aggregate_functions/</guid><description>HoraeDB SQL 基于 DataFusion 实现，支持的聚合函数如下。更多详情请参考： Datafusion
常用 函数 描述 min 最小值 max 最大值 count 求行数 avg 平均值 sum 求和 array_agg 把数据放到一个数组 统计 函数 描述 var / var_samp 返回给定列的样本方差 var_pop 返回给定列的总体方差 stddev / stddev_samp 返回给定列的样本标准差 stddev_pop 返回给定列的总体标准差 covar / covar_samp 返回给定列的样本协方差 covar_pop 返回给定列的总体协方差 corr 返回给定列的相关系数 估值函数 函数 描述 approx_distinct 返回输入值的近似去重数量（HyperLogLog） approx_median 返回输入值的近似中位数，它是 approx_percentile_cont(x, 0.5) 的简单写法 approx_percentile_cont 返回输入值的近似百分位数（TDigest），其中 p 是 0 和 1（包括）之间的 float64，等同于 approx_percentile_cont_with_weight(x, 1, p) approx_percentile_cont_with_weight 返回输入值带权重的近似百分位数（TDigest），其中 w 是权重列表达式，p 是 0 和 1（包括）之间的 float64</description></item><item><title>表操作</title><link>https://horaedb.apache.org/cn/docs/user-guide/operation/table/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/operation/table/</guid><description>HoraeDB 支持标准的 SQL，用户可以使用 Http 协议创建表和读写表。更多内容可以参考 SQL 语法
创建表 示例如下
1 2 3 4 5 curl --location --request POST &amp;#39;http://127.0.0.1:5000/sql&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ -d &amp;#39;{ &amp;#34;query&amp;#34;: &amp;#34;CREATE TABLE `demo` (`name` string TAG, `value` double NOT NULL, `t` timestamp NOT NULL, TIMESTAMP KEY(t)) ENGINE=Analytic with (enable_ttl=&amp;#39;\&amp;#39;&amp;#39;false&amp;#39;\&amp;#39;&amp;#39;)&amp;#34; }&amp;#39; 写数据 示例如下
1 2 3 4 5 curl --location --request POST &amp;#39;http://127.0.0.1:5000/sql&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ -d &amp;#39;{ &amp;#34;query&amp;#34;: &amp;#34;INSERT INTO demo(t, name, value) VALUES(1651737067000, &amp;#39;\&amp;#39;&amp;#39;horaedb&amp;#39;\&amp;#39;&amp;#39;, 100)&amp;#34; }&amp;#39; 读数据 示例如下</description></item><item><title>集群运维</title><link>https://horaedb.apache.org/cn/docs/user-guide/operation/horaemeta/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/operation/horaemeta/</guid><description>集群运维接口的使用前提是，HoraeDB 部署为使用 HoraeMeta 的集群模式。
运维接口 注意： 如下接口在实际使用时需要将 127.0.0.1 替换为 HoraeMeta 的真实地址。
查询表元信息 当 tableNames 不为空的时候，使用 tableNames 进行查询。 当 tableNames 为空的时候，使用 ids 进行查询。使用 ids 查询的时候，schemaName 不生效。 curl --location &amp;#39;http://127.0.0.1:8080/api/v1/table/query&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ -d &amp;#39;{ &amp;#34;clusterName&amp;#34;:&amp;#34;defaultCluster&amp;#34;, &amp;#34;schemaName&amp;#34;:&amp;#34;public&amp;#34;, &amp;#34;names&amp;#34;:[&amp;#34;demo1&amp;#34;, &amp;#34;__demo1_0&amp;#34;], }&amp;#39; curl --location &amp;#39;http://127.0.0.1:8080/api/v1/table/query&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ -d &amp;#39;{ &amp;#34;clusterName&amp;#34;:&amp;#34;defaultCluster&amp;#34;, &amp;#34;ids&amp;#34;:[0, 1] }&amp;#39; 查询表的路由信息 curl --location --request POST &amp;#39;http://127.0.0.1:8080/api/v1/route&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ -d &amp;#39;{ &amp;#34;clusterName&amp;#34;:&amp;#34;defaultCluster&amp;#34;, &amp;#34;schemaName&amp;#34;:&amp;#34;public&amp;#34;, &amp;#34;table&amp;#34;:[&amp;#34;demo&amp;#34;] }&amp;#39; 查询节点对应的 Shard 信息 curl --location --request POST &amp;#39;http://127.</description></item><item><title>黑名单</title><link>https://horaedb.apache.org/cn/docs/user-guide/operation/block_list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://horaedb.apache.org/cn/docs/user-guide/operation/block_list/</guid><description>增加黑名单 如果你想限制某个表的查询，可以把表名加到 read_block_list 中。
示例如下：
1 2 3 4 5 6 7 curl --location --request POST &amp;#39;http://localhost:5000/admin/block&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ -d &amp;#39;{ &amp;#34;operation&amp;#34;:&amp;#34;Add&amp;#34;, &amp;#34;write_block_list&amp;#34;:[], &amp;#34;read_block_list&amp;#34;:[&amp;#34;my_table&amp;#34;] }&amp;#39; 返回结果：
1 2 3 4 { &amp;#34;write_block_list&amp;#34;: [], &amp;#34;read_block_list&amp;#34;: [&amp;#34;my_table&amp;#34;] } 设置黑名单 设置黑名单的操作首先会清理已有的列表，然后再把新的表设置进去。
示例如下：
1 2 3 4 5 6 7 curl --location --request POST &amp;#39;http://localhost:5000/admin/block&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ -d &amp;#39;{ &amp;#34;operation&amp;#34;:&amp;#34;Set&amp;#34;, &amp;#34;write_block_list&amp;#34;:[], &amp;#34;read_block_list&amp;#34;:[&amp;#34;my_table1&amp;#34;,&amp;#34;my_table2&amp;#34;] }&amp;#39; 返回结果：
1 2 3 4 { &amp;#34;write_block_list&amp;#34;: [], &amp;#34;read_block_list&amp;#34;: [&amp;#34;my_table1&amp;#34;, &amp;#34;my_table2&amp;#34;] } 删除黑名单 如果你想把表从黑名单中移除，可以使用如下命令：</description></item></channel></rss>