# Note that the config needs parameters replacement before use, including:
# - CeresMeta addr;
# - Parameters of Aliyun OSS;
# - Kafka boost broker addr;
#
# And one thing deserves explanation that this config is used for running ceresdb docker container:
# ```
# docker run -d --name ceresdb-server \
# -v /etc/ceresdb/ceresdb.toml:{path_to_this_config} \
# ceresdb/ceresdb-server
# ```

[server]
bind_addr = "0.0.0.0"
http_port = 5440
grpc_port = 8831

[logger]
level = "info"

[tracing]
dir = "/home/admin/data/ceresdb"

[runtime]
read_thread_num = 20
write_thread_num = 16
background_thread_num = 12

[cluster_deployment]
mode = "WithMeta"

[cluster_deployment.meta_client]
cluster_name = 'defaultCluster'
meta_addr = 'http://{CeresMetaAddr}:2379'
lease = "10s"
timeout = "5s"

[cluster_deployment.etcd_client]
server_addrs = ['{CeresMetaAddr}:2379']

[analytic]
write_group_worker_num = 16
replay_batch_size = 100
max_replay_tables_per_batch = 128
write_group_command_channel_cap = 1024
sst_background_read_parallelism = 8

[analytic.manifest]
scan_batch_size = 100
snapshot_every_n_updates = 10000
scan_timeout = "5s"
store_timeout = "5s"

[analytic.wal]
type = "Kafka"

[analytic.wal.kafka.client]
boost_broker = "{BoostBrokerAddr}"

[analytic.storage]
mem_cache_capacity = "20GB"
# 1<<8=256
mem_cache_partition_bits = 8

[analytic.storage.object_store]
type = "Aliyun"
key_id = "{KeyID}"
key_secret = "{KeySecret}"
endpoint = "{Endpoint}"
bucket = "{Bucketj}"
prefix = "{DirPrefix}"

[analytic.table_opts]
arena_block_size = 2097152
write_buffer_size = 33554432

[analytic.compaction]
schedule_channel_len = 16
schedule_interval = "30m"
max_ongoing_tasks = 8
memory_limit = "4G"